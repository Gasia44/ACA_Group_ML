{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!conda install -y nomkl > tmp.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import pickle\n",
    "import os\n",
    "import tqdm\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo\n",
    "* https://github.com/Lasagne/Recipes/tree/master/modelzoo\n",
    "* More models within the community\n",
    "* Pick model, copy init, download weights\n",
    "* Here we proceed with vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-05-17 03:07:05--  https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg16.pkl\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.227.83\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.227.83|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 553459517 (528M) [binary/octet-stream]\n",
      "Saving to: ‘vgg16.pkl.1’\n",
      "\n",
      "vgg16.pkl.1           6%[>                   ]  35.57M   844KB/s    eta 9m 53s ^C\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg16.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copyright: see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_3'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_3'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_3'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ostrich, Struthio camelus\n"
     ]
    }
   ],
   "source": [
    "#classes' names are stored here\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "#for example, 10th class is ostrich:\n",
    "print (classes[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to implement two functions in the cell below.\n",
    "\n",
    "Preprocess function should take the image with shape (w, h, 3) and transform it into a tensor with shape (1, 3, 224, 224). Without this transformation, vgg19 won't be able to digest input image. \n",
    "Additionally, your preprocessing function have to rearrange channels RGB -> BGR and subtract mean values from every channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123]).astype(np.uint8)\n",
    "IMAGE_W = 224\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img.copy().astype(np.float32)\n",
    "    \n",
    "    # <substract mean>\n",
    "    img -= MEAN_VALUES\n",
    "    \n",
    "    # <convert RGB to BGR> \n",
    "    img = img[:, :, :: -1]\n",
    "    \n",
    "    #convert from [w,h,3 to 1,3,w,h]\n",
    "    img = np.transpose(img, (2, 0, 1))[None]\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess(img):\n",
    "    img = img.copy().astype(np.float32)\n",
    "    img = img.reshape(img.shape[1:]).transpose((1, 2, 0))\n",
    "    \n",
    "    for i in range(3):\n",
    "        img[:,:, i] += MEAN_VALUES[-1-i]\n",
    "    return img[:, :, :: -1].astype(np.uint8)\n",
    "\n",
    "img = (np.random.rand(IMAGE_W, IMAGE_W, 3) * 256).astype(np.uint8)\n",
    "print (np.linalg.norm(deprocess(preprocess(img)) - img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, the number above will be small, because deprocess function is the inverse of preprocess function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vgg16.pkl', 'rb',) as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "lasagne.layers.set_all_param_values(net['prob'], weights['param values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(net['prob'], input_image, deterministic=True)  # During testing\n",
    "prob = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Давайте проверим, что загруженная сеть работает. Для этого мы скормим ей картину альбатроса и проверим, что она правильно его распознаёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread('sample_images/plate.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "p = prob(preprocess(img))\n",
    "\n",
    "labels = p.ravel().argsort()[-1:-6:-1]\n",
    "print ('top-5 classes are:')\n",
    "for l in labels:\n",
    "    print('%3f\\t%s' % (p.ravel()[l], classes[l].split(',')[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand-quest: Dogs Vs Cats\n",
    "* original competition\n",
    "* https://www.kaggle.com/c/dogs-vs-cats\n",
    "* 25k JPEG images of various size, 2 classes (guess what)\n",
    "\n",
    "### Your main objective\n",
    "* In this seminar your goal is to fine-tune a pre-trained model to distinguish between the two rivaling animals\n",
    "* The first step is to just reuse some network layer as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/d61lupw909hc785/dogs_vs_cats.train.zip?dl=1 -O data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for starters\n",
    "* Train sklearn model, evaluate validation accuracy (should be >80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#extract features from images\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "\n",
    "output = lasagne.layers.get_output(net['fc8'], input_image, deterministic=True)\n",
    "f = theano.function([input_image], output)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "\n",
    "#this may be a tedious process. If so, store the results in some pickle and re-use them.\n",
    "for fname in tqdm(os.listdir('train/')):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    img = imread(\"train/\"+fname)\n",
    "    img = preprocess(imresize(img,(IMAGE_W,IMAGE_W)))\n",
    "    features = f(img)\n",
    "    Y.append(y)\n",
    "    X.append(features)\n",
    "\n",
    "pickle.dump(X, open( \"pickle_X\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 634416.33it/s]\n",
      "/home/xoren/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#extract features from images\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "\n",
    "# Pickled Version\n",
    "# I already pickled my features, and Y into\n",
    "# My features are the output of the \"fc8\" layer from VGG, so they need some further polishing (stacking)\n",
    "\n",
    "X = pickle.load(open( \"pickle_X\", \"rb\" ) )\n",
    "Y = []\n",
    "\n",
    "for fname in tqdm(os.listdir('train/')):\n",
    "    y = fname.startswith(\"cat\")\n",
    "    Y.append(y)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "X = np.asanyarray(X).reshape(25000, 1000)\n",
    "Y = np.asanyarray(Y)\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size = 0.2)\n",
    "X_test, X_validation, Y_test, Y_validation = train_test_split(X_temp, Y_temp, test_size = 0.5)\n",
    "\n",
    "del X_temp\n",
    "del Y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load our dakka__\n",
    "![img](https://s-media-cache-ak0.pinimg.com/564x/80/a1/81/80a1817a928744a934a7d32e7c03b242.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Main quest\n",
    "\n",
    "* Get the score improved!\n",
    "\n",
    "No methods are illegal: ensembling, data augmentation, NN hacks. \n",
    "Just don't let test data slip into training.\n",
    "\n",
    "The main requirement is that you implement the NN fine-tuning recipe:\n",
    "### Split the raw image data\n",
    "  * please do train/validation/test instead of just train/test\n",
    "  * reasonable but not optimal split is 20k/2.5k/2.5k or 15k/5k/5k\n",
    "### Choose which vgg layers are you going to use\n",
    "  * Anything but for prob is okay\n",
    "  * Do not forget that vgg16 uses dropout\n",
    "### Build a few layers on top of chosen \"neck\" layers.\n",
    "  * a good idea is to just stack more layers inside the same network\n",
    "  * alternative: stack on top of get_output\n",
    "### Train the newly added layers for some iterations\n",
    "  * you can selectively train some weights by only sending them to your optimizer\n",
    "      * `lasagne.updates.mysupermegaoptimizer(loss, only_those_weights_i_wanna_train)`\n",
    "  * selecting all weights from the head but not below the neck:\n",
    "      * `all_params = lasagne.layers.get_all_params(new_output_layer_or_layers,trainable=True)`\n",
    "      * `old_params= lasagne.layers.get_all_params(neck_layers,trainable=True)`\n",
    "      * `new_params = [w for w in all_params if w not in old_params]`\n",
    "  * it's cruicial to monitor the network performance at this and following steps\n",
    "### Fine-tune the network body\n",
    "  * probably a good idea to SAVE your new network weights now 'cuz it's easy to mess things up.\n",
    "  * Moreover, saving weights periodically is a no-nonsense idea\n",
    "  * even more cruicial to monitor validation performance\n",
    "  * main network body may need a separate, much lower learning rate\n",
    "      * since updates are dictionaries, one can just compute union\n",
    "      * `updates = {}`\n",
    "      * `updates.update(lasagne.updates.how_i_optimize_old_weights())`\n",
    "      * `updates.update(lasagne.updates.how_i_optimize_old_weights())`\n",
    "      * make sure they do not have overlapping keys. Otherwise, earlier one will be forgotten.\n",
    "      * `assert len(updates) == len(old_updates) + len(new_updates)`\n",
    "### PROFIT!!!\n",
    "  * Evaluate the final score\n",
    "  * Submit to kaggle\n",
    "      * competition page https://www.kaggle.com/c/dogs-vs-cats\n",
    "      * get test data https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "  \n",
    "## Some ways to get bonus points\n",
    "* explore other networks from the model zoo\n",
    "* play with architecture\n",
    "* 85%/90%/93%/95%/97% kaggle score (screen pls).\n",
    "* data augmentation, prediction-time data augmentation\n",
    "* use any more advanced fine-tuning technique you know/read anywhere\n",
    "* ml hacks that benefit the final score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1000)\n",
      "(2500, 1000)\n",
      "(2500, 1000)\n",
      "(20000,)\n",
      "(2500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# To make sure I devided data properly\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=True, random_state=None, solver='auto',\n",
       "        tol=0.001)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit RidgeClassifier\n",
    "\n",
    "ridge = RidgeClassifier(normalize=True, copy_X=True)\n",
    "ridge.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9764\n"
     ]
    }
   ],
   "source": [
    "print(ridge.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976\n"
     ]
    }
   ],
   "source": [
    "print(ridge.score(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I get very good results by just applying Ridge regression, so any other modification will only make a more \n",
    "# convoluted model with little to no gain in prediction accurecy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
